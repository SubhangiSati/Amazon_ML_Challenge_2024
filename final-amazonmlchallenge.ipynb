{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9408303,"sourceType":"datasetVersion","datasetId":5712595},{"sourceId":9408433,"sourceType":"datasetVersion","datasetId":5712697},{"sourceId":9409028,"sourceType":"datasetVersion","datasetId":5713194}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install easyocr","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:18:11.650801Z","iopub.execute_input":"2024-09-16T02:18:11.651275Z","iopub.status.idle":"2024-09-16T02:18:25.973439Z","shell.execute_reply.started":"2024-09-16T02:18:11.651224Z","shell.execute_reply":"2024-09-16T02:18:25.972320Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: easyocr in /opt/conda/lib/python3.10/site-packages (1.7.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr) (2.4.0)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.19.0)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr) (4.10.0.84)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.14.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from easyocr) (9.5.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.23.2)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.6.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from easyocr) (6.0.2)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.8.5.post1)\nRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.3.0.post5)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.1.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->easyocr) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"OCR EXTRACTION FOR TEST IMAGES","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport easyocr\n\n# Initialize the OCR reader\nreader = easyocr.Reader(['en'])  # Use English for OCR\n\n# Directory containing the images\nimage_dir = '/kaggle/input/test-amazonml/Test'\n\n# Create a list to store the extracted text\nresults = []\n\n# Iterate over all the images in the directory\nfor idx, image_file in enumerate(sorted(os.listdir(image_dir))):\n    # Get the full path to the image\n    image_path = os.path.join(image_dir, image_file)\n\n    # Perform OCR on the image\n    try:\n        # Extract text using EasyOCR\n        ocr_result = reader.readtext(image_path, detail=0)  # detail=0 returns only text\n        \n        # Join the extracted text into a single string separated by commas\n        extracted_text = ', '.join(ocr_result)\n        \n        # Append the result to the list\n        results.append({'index': idx, 'predictions': extracted_text})\n    \n    except Exception as e:\n        # In case of error, log the error and save an empty string for this image\n        print(f\"Error processing image {image_path}: {e}\")\n        results.append({'index': idx, 'predictions': ''})\n\n# Convert results to a DataFrame\ndf_results = pd.DataFrame(results)\n\n# Save the results to a CSV file if needed\ndf_results.to_csv('ocr_extracted_text_test_easyocr.csv', index=False)\n\n# Display the DataFrame\nprint(df_results)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-16T02:18:30.080890Z","iopub.execute_input":"2024-09-16T02:18:30.081250Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n/opt/conda/lib/python3.10/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=device))\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","output_type":"stream"}]},{"cell_type":"markdown","source":"OCR EXTRACTION ON TRAIN SET","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport easyocr\n\n# Initialize the OCR reader\nreader = easyocr.Reader(['en'])  # Use English for OCR\n\n# Directory containing the images\nimage_dir = '/kaggle/input/train-amazonml/Train'\n\n# Create a list to store the extracted text\nresults = []\n\n# Iterate over all the images in the directory\nfor idx, image_file in enumerate(sorted(os.listdir(image_dir))):\n    # Get the full path to the image\n    image_path = os.path.join(image_dir, image_file)\n\n    # Perform OCR on the image\n    try:\n        # Extract text using EasyOCR\n        ocr_result = reader.readtext(image_path, detail=0)  # detail=0 returns only text\n        \n        # Join the extracted text into a single string separated by commas\n        extracted_text = ', '.join(ocr_result)\n        \n        # Append the result to the list\n        results.append({'index': idx, 'predictions': extracted_text})\n    \n    except Exception as e:\n        # In case of error, log the error and save an empty string for this image\n        print(f\"Error processing image {image_path}: {e}\")\n        results.append({'index': idx, 'predictions': ''})\n\n# Convert results to a DataFrame\ndf_results = pd.DataFrame(results)\n\n# Save the results to a CSV file if needed\ndf_results.to_csv('ocr_extracted_text_easyocr.csv', index=False)\n\n# Display the DataFrame\nprint(df_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ML MODEL ON THE EXTRACTED TEXT FOR PREDICTION OF ENTITY OF TEST SET","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom src.constants import entity_unit_map\n\ndef preprocess_text(text):\n    if pd.isna(text):\n        return \"\"\n    text = str(text)\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    return text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_entity_value(text, entity_name):\n    if pd.isna(text):\n        return None\n    text = str(text)\n    \n    if entity_name in entity_unit_map:\n        units = entity_unit_map[entity_name]\n        # First, try to find a number with any of the units\n        for unit in units:\n            pattern = rf'(\\d+(?:\\.\\d+)?)\\s*{re.escape(unit)}'\n            match = re.search(pattern, text, re.IGNORECASE)\n            if match:\n                return f\"{match.group(1)} {unit}\"\n        \n        # If no unit is found, just extract the first number and use any unit\n        number_match = re.search(r'\\d+(?:\\.\\d+)?', text)\n        if number_match:\n            return f\"{number_match.group()} {next(iter(units))}\"\n    \n    # For entities without specific units, just extract the first number\n    number_match = re.search(r'\\d+(?:\\.\\d+)?', text)\n    return number_match.group() if number_match else None\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(train_df, ocr_df):\n    try:\n        merged_df = pd.merge(train_df, ocr_df, on='index')\n        merged_df['processed_text'] = merged_df['predictions'].apply(preprocess_text)\n        \n        X = merged_df['processed_text']\n        y = merged_df['entity_name']\n        \n        model = Pipeline([\n            ('tfidf', TfidfVectorizer()),\n            ('clf', MultinomialNB())\n        ])\n        model.fit(X, y)\n        \n        return model\n    except Exception as e:\n        print(f\"Error in train_model: {str(e)}\")\n        raise","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_entity_values(model, test_df, ocr_df):\n    try:\n        merged_df = pd.merge(test_df, ocr_df, on='index')\n        merged_df['processed_text'] = merged_df['predictions'].apply(preprocess_text)\n        \n        predicted_values = []\n        for idx, row in merged_df.iterrows():\n            entity_name = row['entity_name']\n            value = extract_entity_value(row['predictions'], entity_name)\n            predicted_values.append(value)\n        \n        # Create a new DataFrame with only 'index' and 'predictions' columns\n        results_df = pd.DataFrame({\n            'index': merged_df['index'],\n            'predictions': predicted_values\n        })\n        \n        return results_df\n    except Exception as e:\n        print(f\"Error in predict_entity_values: {str(e)}\")\n        raise","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main():\n    try:\n        train_df = pd.read_csv('/kaggle/input/csv-for-amazon-ml-challenge/train.csv')\n        ocr_train_df = pd.read_csv('ocr_extracted_text_easyocr.csv')\n        test_df = pd.read_csv('/kaggle/input/csv-for-amazon-ml-challenge/test.csv')  # Assuming you have a test.csv file\n        ocr_test_df = pd.read_csv('ocr_extracted_text_test_easyocr.csv')\n        \n        model = train_model(train_df, ocr_train_df)\n        results_df = predict_entity_values(model, test_df, ocr_test_df)\n        \n        # Save results with only 'index' and 'predictions' columns\n        results_df.to_csv('test_predictions.csv', index=False)\n        print(\"Predictions saved to 'test_predictions.csv'\")\n    except Exception as e:\n        print(f\"Error in main function: {str(e)}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{},"execution_count":null,"outputs":[]}]}