{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEmGBCNVxRLM"
      },
      "source": [
        "# **AMAZON ML CHALLENGE**\n",
        "# `- BY THE DECODERS`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9R0S44AxPH0"
      },
      "source": [
        "STEP 1. Download and Preprocess Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb-Z3LaMwz7y",
        "outputId": "332b00c8-1ded-43ec-dd9c-8c5a33c36223"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "\n",
        "# Function to download a single image\n",
        "def download_image(url, save_path):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img.save(save_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading image from {url}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Function to download all images from a CSV\n",
        "def download_images(csv_file, image_dir):\n",
        "    # Create the image directory if it doesn't exist\n",
        "    if not os.path.exists(image_dir):\n",
        "        os.makedirs(image_dir)\n",
        "\n",
        "    # Load the CSV file\n",
        "    data = pd.read_csv(csv_file)\n",
        "\n",
        "    # Ensure there is an 'index' column (using DataFrame index if not present)\n",
        "    if 'index' not in data.columns:\n",
        "        data['index'] = data.index\n",
        "\n",
        "    # Iterate over the rows and download images\n",
        "    for idx, row in data.iterrows():\n",
        "        url = row['image_link']\n",
        "        img_name = f\"{row['index']}.jpg\"\n",
        "        save_path = os.path.join(image_dir, img_name)\n",
        "        success = download_image(url, save_path)\n",
        "        if success:\n",
        "            print(f\"Downloaded {img_name}\")\n",
        "        else:\n",
        "            print(f\"Failed to download {img_name}\")\n",
        "\n",
        "# Paths to CSV files and directories to save images\n",
        "train_csv_path = 'dataset\\\\train.csv'\n",
        "test_csv_path = 'dataset\\\\test.csv'\n",
        "train_image_dir = 'ML Images\\\\Train'\n",
        "test_image_dir = 'ML Images\\\\Test'\n",
        "\n",
        "# Download images for train and test datasets\n",
        "# download_images(train_csv_path, train_image_dir)\n",
        "download_images(test_csv_path, test_image_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow3woXtkz4c2",
        "outputId": "e6fa8832-7bc4-4529-ae1e-f7799165b491"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "train_df = pd.read_csv('dataset\\\\train.csv')\n",
        "\n",
        "# Inspect the columns\n",
        "print(train_df.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUYi8gSxxq5b"
      },
      "source": [
        " STEP-2 Extract Text using OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74ad75O8xvY9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pytesseract\n",
        "import cv2\n",
        "import pandas as pd\n",
        "\n",
        "# Set the path to your Tesseract executable\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'  # Adjust this path if necessary\n",
        "\n",
        "# Paths to the image directories\n",
        "train_image_dir = 'ML Images\\\\Sample_Train'\n",
        "test_image_dir = 'ML Images\\\\Sample_Test'\n",
        "\n",
        "def perform_ocr(image_dir):\n",
        "    \"\"\"\n",
        "    Perform OCR on all images in the specified directory.\n",
        "    \n",
        "    Parameters:\n",
        "        image_dir (str): Path to the directory containing images.\n",
        "    \n",
        "    Returns:\n",
        "        results (list): A list of tuples (index, prediction).\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    index = 0\n",
        "\n",
        "    # Iterate through each image file in the directory\n",
        "    for filename in os.listdir(image_dir):\n",
        "        image_path = os.path.join(image_dir, filename)\n",
        "        \n",
        "        # Read the image\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"Warning: Could not read image {filename}\")\n",
        "            results.append((index, \"\"))\n",
        "            index += 1\n",
        "            continue\n",
        "\n",
        "        # Perform OCR using pytesseract\n",
        "        ocr_result = pytesseract.image_to_string(image)\n",
        "        \n",
        "        # Clean and format the OCR result\n",
        "        if ocr_result.strip():\n",
        "            # Convert multiline text to a single comma-separated string\n",
        "            formatted_text = ', '.join([line.strip() for line in ocr_result.splitlines() if line.strip()])\n",
        "        else:\n",
        "            formatted_text = \"\"\n",
        "\n",
        "        # Append the result to the list\n",
        "        results.append((index, formatted_text))\n",
        "        index += 1\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Perform OCR on Train and Test images\n",
        "train_results = perform_ocr(train_image_dir)\n",
        "test_results = perform_ocr(test_image_dir)\n",
        "\n",
        "# Combine train and test results (if needed, modify based on requirement)\n",
        "# combined_results = train_results + test_results\n",
        "\n",
        "# Create a DataFrame and save to CSV\n",
        "df = pd.DataFrame(train_results, columns=['index', 'prediction'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Output CSV file path\n",
        "output_csv = 'D:\\\\Amazon ML Challenge\\\\student_resource 3\\\\ocr_output.csv'\n",
        "\n",
        "df.to_csv(output_csv, index=False)\n",
        "\n",
        "print(f\"OCR processing completed. Results saved to {output_csv}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EXTRACT TEXT USING VIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import ViTForImageClassification\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Custom Dataset class\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "        # Ensure entity_name and entity_value are strings\n",
        "        self.data_frame['entity_name'] = self.data_frame['entity_name'].astype(str)\n",
        "        self.data_frame['entity_value'] = self.data_frame['entity_value'].astype(str)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, f\"{self.data_frame.iloc[idx, 0]}.jpg\")  # Ensure proper file extension\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        \n",
        "        entity_name = self.data_frame.iloc[idx, 3]  # Index of entity_name\n",
        "        entity_value = self.data_frame.iloc[idx, 4]  # Index of entity_value\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, entity_name, entity_value\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_dataset = CustomDataset(csv_file='ML Images\\\\sample_train.csv', img_dir='ML Images\\\\Sample_Train', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import ViTForImageClassification\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class CustomViTModel(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(CustomViTModel, self).__init__()\n",
        "        self.vit = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=num_labels)\n",
        "    \n",
        "    def forward(self, images):\n",
        "        return self.vit(images).logits\n",
        "\n",
        "# Initialize model\n",
        "num_labels = len(train_dataset.data_frame['entity_name'].unique())  # Example number of labels, adjust as needed\n",
        "model = CustomViTModel(num_labels=num_labels)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct_predictions = 0\n",
        "        total_predictions = 0\n",
        "\n",
        "        for images, entity_names, entity_values in dataloader:\n",
        "            # Map entity_names to numerical labels\n",
        "            labels = torch.tensor([name_to_label[name] for name in entity_names], dtype=torch.long)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Compute predictions\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            # Update counts for accuracy\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "            total_predictions += labels.size(0)\n",
        "            \n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item() * images.size(0)\n",
        "        \n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        epoch_accuracy = correct_predictions / total_predictions\n",
        "        \n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "# Example label encoding dictionary\n",
        "name_to_label = {name: idx for idx, name in enumerate(train_dataset.data_frame['entity_name'].unique())}\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, criterion, optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'vit_model.pth')\n",
        "print(\"Model saved to 'vit_model.pth'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = CustomViTModel(num_labels=num_labels)\n",
        "model.load_state_dict(torch.load('vit_model.pth'))\n",
        "model.eval()\n",
        "print(\"Model loaded from 'vit_model.pth'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# Define the test dataset class\n",
        "class TestDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data_frame = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Ensure entity_name is a string\n",
        "        self.data_frame['entity_name'] = self.data_frame['entity_name'].astype(str)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, f\"{self.data_frame.iloc[idx, 0]}.jpg\")  # Ensure proper file extension\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        \n",
        "        entity_name = self.data_frame.iloc[idx, 1]  # Index of entity_name\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, entity_name\n",
        "\n",
        "# Load test dataset\n",
        "test_dataset = TestDataset(csv_file='ML Images\\\\sample_Test.csv', img_dir='ML Images\\\\Sample_Test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ANOTHER APPROACH FOR THE ABOVE ONE ONLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     index                                        predictions\n",
            "0        0       PROPSS’ N RE INGREDIENT MENAGER 100% NATUREL\n",
            "1        1                  LEBENSMITTELECHT GEPRAGTES DESIGN\n",
            "2        2  G 4@m® Das Material ist ca. 5mm dick und die F...\n",
            "3        3  Nature’s Way To Wellness “N91 . y, @ EASY TO S...\n",
            "4        4  KIM JOHANSON Kaufe 3 Produkte von uns und spar...\n",
            "..     ...                                                ...\n",
            "196    196                                                   \n",
            "197    197  iscover wellness GREEN COFFEE (| BURNFAT __) F...\n",
            "198    198  GREEN COFFEE Helps Control Supports Blood by A...\n",
            "199    199  16G Thick High Grade 304 Stainless Steel \\ \\ a...\n",
            "200    200  cg @ Puppyiser WITH CHICKEN SHPURINA? @ PuPPYi...\n",
            "\n",
            "[201 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "\n",
        "# Path to the directory containing images\n",
        "images_path = 'ML Images\\\\Sample_Train'\n",
        "\n",
        "# Path to the Tesseract executable (if required, usually on Windows)\n",
        "# Uncomment and set the path if necessary\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
        "\n",
        "# Initialize an empty list to store the results\n",
        "results = []\n",
        "\n",
        "# Iterate over each image in the directory\n",
        "for idx, image_file in enumerate(os.listdir(images_path)):\n",
        "    # Construct the full image path\n",
        "    image_path = os.path.join(images_path, image_file)\n",
        "    \n",
        "    # Read the image using OpenCV\n",
        "    image = cv2.imread(image_path)\n",
        "    \n",
        "    # Convert the image to grayscale (optional, improves OCR accuracy)\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Apply some preprocessing if needed (e.g., thresholding)\n",
        "    # _, preprocessed_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY)\n",
        "    \n",
        "    # Perform OCR on the image using Tesseract\n",
        "    extracted_text = pytesseract.image_to_string(gray_image)\n",
        "    \n",
        "    # Clean up the extracted text (remove line breaks, extra spaces, etc.)\n",
        "    cleaned_text = ' '.join(extracted_text.split()).strip()\n",
        "    \n",
        "    # Append the result to the list as (index, predictions)\n",
        "    results.append({'index': idx, 'predictions': cleaned_text})\n",
        "\n",
        "# Create a DataFrame from the results\n",
        "df_results = pd.DataFrame(results, columns=['index', 'predictions'])\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optionally, save the DataFrame to a CSV file\n",
        "df_results.to_csv('ocr_extracted_text.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   index prediction\n",
            "0      0           \n",
            "1      1           \n",
            "2      2           \n",
            "3      3           \n",
            "4      4           \n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from src.constants import entity_unit_map, allowed_units  # Import from constants.py\n",
        "\n",
        "# Load the DataFrame containing OCR extracted text\n",
        "df_results = pd.read_csv('ocr_extracted_text.csv')\n",
        "\n",
        "# Initialize an empty list to store the final predictions\n",
        "final_predictions = []\n",
        "\n",
        "# Define a function to extract values and units from text\n",
        "def extract_value_and_unit(text):\n",
        "    # Ensure the text is a string\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # Define regular expression to find numerical values followed by units\n",
        "    # Example pattern: \"34 gram\", \"12.5 centimetre\"\n",
        "    pattern = r'(\\d+\\.?\\d*)\\s*([a-zA-Z]+)'\n",
        "    \n",
        "    # Find all matches in the text\n",
        "    matches = re.findall(pattern, text)\n",
        "    \n",
        "    # Process each match to find valid value and unit\n",
        "    for match in matches:\n",
        "        value, unit = match\n",
        "        \n",
        "        # Check if the unit is in the allowed units\n",
        "        if unit in allowed_units:\n",
        "            # Return the first valid match found\n",
        "            return f\"{float(value)} {unit}\"\n",
        "    \n",
        "    # If no valid match is found, return an empty string\n",
        "    return \"\"\n",
        "\n",
        "# Iterate over each row in the DataFrame to extract values and units\n",
        "for _, row in df_results.iterrows():\n",
        "    # Get the extracted text from the 'predictions' column\n",
        "    extracted_text = row['predictions']\n",
        "    \n",
        "    # Extract the value and unit from the text\n",
        "    prediction = extract_value_and_unit(extracted_text)\n",
        "    \n",
        "    # Append the result to the final predictions list\n",
        "    final_predictions.append(prediction)\n",
        "\n",
        "# Add the final predictions to the DataFrame\n",
        "df_results['prediction'] = final_predictions\n",
        "\n",
        "# Drop the original 'predictions' column if not needed\n",
        "df_results.drop(columns=['predictions'], inplace=True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df_results.head())\n",
        "\n",
        "# Save the final DataFrame to a CSV file\n",
        "df_results.to_csv('final_predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OCR EXTRACTION USING EASY-OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     index                                        predictions\n",
            "0        0  PROPOS', NATUREJ, INGREDIENT MENAGER, MULTI-US...\n",
            "1        1  TrLeeda=_, Uer, R, RRIFIC;, LEBENSMITTELECHT, ...\n",
            "2        2  GroBe Kapazicat; Tragiahigkeit bis zu 30KG, Da...\n",
            "3        3  Nature' s, Way To Wellness, Ir1Q1, EASY TO, SW...\n",
            "4        4  KIM JOHANSON, Kaufe 3 Produkte von, uns und sp...\n",
            "..     ...                                                ...\n",
            "196    196                                               8, 2\n",
            "197    197  NHerbal max, Di5 € 0 V e [, w eilne $ s, GREEN...\n",
            "198    198  Herbal max, BENEFITS OF GREEN COFFEE, Di $ € 0...\n",
            "199    199  166 Thick High Grade 304 Stainless Steel, Anti...\n",
            "200    200  NEW, 00s Food OnLT, #, NEW, RPURINAP, @, SUPER...\n",
            "\n",
            "[201 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "\n",
        "# Initialize the OCR reader\n",
        "reader = easyocr.Reader(['en'])  # Use English for OCR\n",
        "\n",
        "# Directory containing the images\n",
        "image_dir = 'ML Images\\\\Sample_Train'\n",
        "\n",
        "# Create a list to store the extracted text\n",
        "results = []\n",
        "\n",
        "# Iterate over all the images in the directory\n",
        "for idx, image_file in enumerate(sorted(os.listdir(image_dir))):\n",
        "    # Get the full path to the image\n",
        "    image_path = os.path.join(image_dir, image_file)\n",
        "\n",
        "    # Perform OCR on the image\n",
        "    try:\n",
        "        # Extract text using EasyOCR\n",
        "        ocr_result = reader.readtext(image_path, detail=0)  # detail=0 returns only text\n",
        "        \n",
        "        # Join the extracted text into a single string separated by commas\n",
        "        extracted_text = ', '.join(ocr_result)\n",
        "        \n",
        "        # Append the result to the list\n",
        "        results.append({'index': idx, 'predictions': extracted_text})\n",
        "    \n",
        "    except Exception as e:\n",
        "        # In case of error, log the error and save an empty string for this image\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        results.append({'index': idx, 'predictions': ''})\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save the results to a CSV file if needed\n",
        "df_results.to_csv('ocr_extracted_text_easyocr.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   index                                           ocr_text  entity_name  \\\n",
            "0      0  propos', naturej, ingredient menager, multi-us...  item_weight   \n",
            "1      1  trleeda=_, uer, r, rrific;, lebensmittelecht, ...  item_volume   \n",
            "2      2  grobe kapazicat; tragiahigkeit bis zu 30kg, da...  item_weight   \n",
            "3      3  nature' s, way to wellness, ir1q1, easy to, sw...  item_weight   \n",
            "4      4  kim johanson, kaufe 3 produkte von, uns und sp...  item_weight   \n",
            "\n",
            "  matched_value  \n",
            "0           ton  \n",
            "1                \n",
            "2                \n",
            "3                \n",
            "4                \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load the train.csv and ocr_extracted.csv\n",
        "train_df = pd.read_csv('ML Images\\\\sample_train.csv')\n",
        "ocr_df = pd.read_csv('ocr_extracted_text_easyocr.csv')\n",
        "\n",
        "# Import allowed units from constants.py (assuming constants.py is in the current directory)\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon', 'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Flatten the units into a single set\n",
        "allowed_units = {unit for units in entity_unit_map.values() for unit in units}\n",
        "\n",
        "# Create a list to store matched entity names and their values\n",
        "matched_entities = []\n",
        "\n",
        "# Iterate through each row in train.csv\n",
        "for idx, row in train_df.iterrows():\n",
        "    index = row['index']\n",
        "    entity_name = row['entity_name']\n",
        "    entity_value = str(row['entity_value']).strip().lower()\n",
        "    \n",
        "    # Find the corresponding OCR text using the index\n",
        "    ocr_text = ocr_df.loc[ocr_df['index'] == index, 'predictions'].values\n",
        "    if len(ocr_text) == 0:\n",
        "        matched_entities.append({'index': index, 'ocr_text': '', 'entity_name': entity_name, 'matched_value': ''})\n",
        "        continue\n",
        "    \n",
        "    # Join the OCR text into one string and lowercase it\n",
        "    ocr_text_str = ', '.join(ocr_text).lower()\n",
        "\n",
        "    # Search for numerical values in the OCR text\n",
        "    number_matches = re.findall(r'\\b\\d+(\\.\\d+)?\\b', ocr_text_str)\n",
        "    \n",
        "    # Search for allowed units in the OCR text\n",
        "    unit_matches = [unit for unit in allowed_units if unit in ocr_text_str]\n",
        "    \n",
        "    # Try to find exact match from extracted text to entity_value in train.csv\n",
        "    exact_match_found = False\n",
        "    matched_value = ''\n",
        "\n",
        "    # Check combinations of numbers and units\n",
        "    for number in number_matches:\n",
        "        for unit in unit_matches:\n",
        "            combined_value = f\"{number} {unit}\"\n",
        "            if combined_value == entity_value:\n",
        "                matched_value = combined_value\n",
        "                exact_match_found = True\n",
        "                break\n",
        "        if exact_match_found:\n",
        "            break\n",
        "\n",
        "    # If no exact match, use the first found number and unit as a fallback\n",
        "    if not exact_match_found:\n",
        "        if number_matches and unit_matches:\n",
        "            matched_value = f\"{number_matches[0]} {unit_matches[0]}\"\n",
        "        elif number_matches:\n",
        "            matched_value = number_matches[0]\n",
        "        elif unit_matches:\n",
        "            matched_value = unit_matches[0]\n",
        "    \n",
        "    # Append the result to the matched entities list\n",
        "    matched_entities.append({\n",
        "        'index': index,\n",
        "        'ocr_text': ocr_text_str,\n",
        "        'entity_name': entity_name,\n",
        "        'matched_value': matched_value\n",
        "    })\n",
        "\n",
        "# Convert matched entities to a DataFrame\n",
        "matched_df = pd.DataFrame(matched_entities)\n",
        "\n",
        "# Save matched DataFrame for reference\n",
        "matched_df.to_csv('matched_entities_with_units.csv', index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(matched_df.head())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
